[
  {
    "id": 2,
    "title": "Wait, How Much Does That AI Agent Actually Cost?",
    "description": "A candid conversation on the launch of Project SustAInd between two Junior Research Fellows, Aneetta and Chandrasekar, at the Software Engineering Research Center (SERC) Lab, IIIT Hyderabad.",
    "content": "**A candid conversation on the launch of Project SustAInd.**\n\n*(Scene: Two Junior Research Fellows, Aneetta and Chandrasekar, taking a break at the Software Engineering Research Center (SERC) Lab, IIIT Hyderabad.)*\n\n*Aneetta:*\nOkay, Chandru, serious question. I was scrolling through my phone today, and everyone is obsessed with \"Agentic AI\". Autonomous agents planning trips, writing code, calling tools... it's everywhere. But is anyone talking about the bill?\n\n*Chandrasekar:*\nThe cloud bill? Or the electricity bill?\n\n*Aneetta:*\nBoth! And the carbon bill. Think about it! AI is no longer just a specialized tool for isolated tasks, it has become the foundational fabric running through every industry. And specifically with Agentic AI, we aren't just looking at systems that predict text anymore. We are looking at systems that act. They have the potential to become the active engine behind education, healthcare, governance, you name it.\n\n*Chandrasekar:*\nExactly. And that's the scary part. [According to a study, training a single state-of-the-art AI model can emit as much carbon dioxide as the lifetime emissions of five cars](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/). But agents are worse. They don't just answer once; they loop, they reason, they retry. [On an average, even a simple generative query consumes nearly 10 times the energy of a standard web search](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand).\n\n*Aneetta:*\nAnd that's exactly why we're here, right? Welcome to [**SustAInd**](https://sa4s-serc.github.io/sustaind/) (Sustainable AI for India).\n\n*Chandrasekar:*\nFinally! It feels good to officially talk about it. For those reading this who don't know us, we are a government-backed initiative supported by [ANRF](https://www.anrfonline.in/ANRF/HomePage) and [PM-ECRG](https://www.anrfonline.in/ANRF/ecrg_anrf), led by Dr. Karthik Vaidhyanathan here at the [SA4S Research Group](https://sa4s-serc.github.io/), [SERC lab](https://serc.iiit.ac.in/), [IIIT Hyderabad](https://www.iiit.ac.in/).\n\n*Aneetta:*\nThe mission is huge. We aren't just trying to shrink the models. We are trying to fix the software ecosystem around it. But Chandru, explain it to the readers: why is this different from just \"buying better GPUs\"?\n\n*Chandrasekar:*\nHardware solves how fast the system runs, but software decides how efficiently it runs. It's the invisible layer where we usually lose the most energy. We are building a framework based on three pillars, and we need all three to work together:\n\nüåç**Environmental:** *We need to measure the carbon footprint not just when we train the model, but when the software actually runs.*\n\nüí∞**Economic:** *This is the silent killer. [Did you know nearly 85% of AI projects fail to deliver value?](https://www.forbes.com/councils/forbestechcouncil/2024/11/15/why-85-of-your-ai-models-may-fail/). If it costs too much to run, it dies.*\n\n‚öôÔ∏è**Technical:** *Code rot. Dependency hell. If the system isn't modular and maintainable, it's not sustainable.*\n\n*Aneetta:*\nThat's the \"Software-Centric\" approach we keep talking about. It's like building a house. You can have the best bricks (*the AI Model*), but if the construction (*the Software Development*) is bad, the house leaks energy and eventually collapses.\n\n*Chandrasekar:*\nPrecisely. That's why our deliverables aren't just papers. We are building:\n\n**Energy Profiling Tools:** *So developers can actually see their energy consumption, cost, and technical debt in real-time.*\n\n**Green AI Design Guidelines:** *A playbook for architects and policymakers to ensure every system balances all three pillars.*\n\n**A GreenAI Lab:** *Right here at IIITH to validate our novel approaches through real-world experiments.*\n\n*Aneetta:*\nSpeaking of novel approaches, we've already started! We presented our first paper, [HarmonE, at ECSA 2025](https://link.springer.com/chapter/10.1007/978-3-032-02138-0_3). It's our first step toward architectural patterns that actually care about energy.\n\n*Chandrasekar:*\nIt's a team effort, obviously. It's not just us.\n\n*Aneetta:*\nOh, definitely. [It's Dr. Karthik steering the ship, plus Akhila (PhD), Hiya (MS), and the dual-degree wizards Shaunak and Arihant.](https://sa4s-serc.github.io/sustaind/people) It's a mix of software engineers, AI researchers, and system architects.\n\n*Chandrasekar:*\nSo, what's the ask, Aneetta? We want people to get involved, right?\n\n*Aneetta:*\n100%. This isn't just an academic exercise. If you are a developer, we want you to test our profiling tools. If you are an educator, we want to help you teach \"Green AI\" concepts. If you are a policymaker, we want to provide the data you need to set standards for India.\n\n*Chandrasekar:*\nAgentic AI is the future, no doubt. But whether that future is expensive and dirty, or efficient and sustainable... that depends on how we build the software today.\n\n*Aneetta:*\nWell put. So, to our readers: Watch this space. We'll be sharing our tools, our failures, and our wins.\n\n*Chandrasekar:*\nAnd if you want to collaborate, challenge our ideas, or just geek out over sustainability metrics, reach out to us.\n\n---\n\n## Join the SustAInd Mission !!\n\nExplore team details, updates, and publications on our official page: üîó[https://sa4s-serc.github.io/sustaind/](https://sa4s-serc.github.io/sustaind/)\n\n---\n\n*Aneetta:*\nSo, Chandru‚Ä¶ our first blog published?\n\n*Chandrasekar:*\nYep! And hopefully, the first of many. Onward to building a greener AI ecosystem for India. üå±",
    "author": "Aneetta Mariam Varghese & Chandrasekar Sureshkumar",
    "date": "2025-12-05",
    "readTime": "5 min read"
  },
  {
    "id": 1,
    "title": "Enhancing Sustainability of Modern Software Systems through Self-adaptive Architectures",
    "description": "Dr. Karthik Vaidhyanathan explains the concept of software sustainability and how his group's research on self-adaptation is contributing towards greener and sustainable software.",
    "content": "Imagine receiving an alert that your system has gone down or is consuming an unsustainable amount of power (Yes, you heard that right!). The immediate response is to identify and resolve the issue ‚Äì whether it's a sudden spike in user traffic, unexpected resource constraints, or a misconfiguration. But what if the system could adapt itself dynamically, anticipating and mitigating these problems in real-time? Modern software systems including AI Systems are subjected to various types of uncertainties ranging from unpredictable user behaviors and fluctuating workloads to resource constraints in the operating environments, evolving security threats and real-world variability in data inputs. Studies show that **64% of system outages result from misconfigurations**^1^. And **91% of AI models degrade over time**^2^. Beyond impacting reliability and performance, these uncertainties also have a huge impact on the environment (increase in user loads may trigger the need to add more resources). Recent estimates from Green Software Foundation^3^ highlight that software emissions are equivalent to the emissions of air, rail and shipping combined. As researchers trying to work in the intersection of software architecture and ML, we are constantly trying to enhance the sustainability of modern software systems including AI-enabled systems. One way we have attempted to tackle this problem is by making systems **self-adaptive** where they adapt their structure or behavior with minimal human intervention.\n\n## Enhancing Sustainability through Self-adaptation\n\nMore often than not, people often associate sustainability with making things green. While it's not incorrect, it's not the only aspect of sustainability. It is a **multi-dimensional quality attribute** which encompasses the technical, environmental, social and economical aspects of a running software system. My research on using self-adaptation to dynamically adapt software systems at runtime to enhance sustainability started during my PhD where the focus was to continuously monitor the metrics of a running software system, identify any potential uncertainties using AI and further use AI to dynamically reconfigure the system to handle the uncertainty. We had applied this concept to IoT systems where we used AI to dynamically switch the processing between edge, fog and cloud to save battery power of IoT devices while guaranteeing system performance^4^. That's when we realized that the idea could be applied to a broader class of software systems.\n\nMost of the organizations today are adopting a **microservice-based architectural style** where each service is designed around domain boundaries and team compositions. At the same time organizations have realized/are starting to realize the importance of monitoring their carbon footprint and further reducing emissions. In this context, we developed an approach that uses self-adaptive mechanisms to dynamically decide which microservice instance to use to guarantee trade-off between latency and energy consumption. To illustrate how this works, consider a scenario where a user located in Hyderabad sends a request to login to an e-commerce application. Typically such a request will be served by an instance of the microservice that is located in a data center closer to the location of the user inorder to guarantee quicker response. However, that instance might be located in a data center which is powered by fossil fuel or the instance might be consuming higher power due to several incoming requests. Hence, it might be beneficial to serve the request from some other instance which is consuming less power and is located in a data center powered by renewable energy but at the compromise of the network latency that may come in due to the location. With this broad thought, we developed an approach that leverages the use of **reinforcement learning** to decide which microservice instance to use to serve a user request by considering the trade-off between response time and energy consumption. This work has been published in top tier international conferences^5^. Further, we also extended this concept to serverless functions in our recently published work where it was more about deciding the optimal instance to use to allocate a serverless function considering trade-off between cost and performance^6^.\n\n## Extending to AI-enabled Systems\n\nThe emergence of AI has enhanced various walks of our life albeit with a significant cost in terms of the environmental impact. Estimates suggest that **data centers already consume 2% of the world's electricity** requiring gallons of fresh water with AI taking the bulk of the load and these numbers are only expected to increase^7^. To this end, we believe self-adaptive systems can certainly play a role in enhancing the sustainability of AI systems without compromising on the performance of the system or accuracy of the AI models. For any task today, there are various types of AI models that could be used. For example, if we want to chat, we have ChatGPT or Claude or Llama or Gemini to name a few. Similarly for tasks like object detection, we have different varieties of AI models such as the Yolo family of models or the detectron series, etc. Most of the times we don't need complex AI models, all we need is simple AI models but for some scenarios we may need complex AI models that can provide high accuracy. Based on this thought process, as a starting point, we developed an approach, **Eco-MLS**^8^, that presents the architecture of an ML system that leverages the concept of self-adaptation, switching between different AI models at run-time to trade-off between accuracy and energy consumption. We took object detection as our domain and we developed a self-adaptive ML system that switches between different object detection models at runtime by deciding when to use what models without compromising on the accuracy while simultaneously reducing power consumption. We noticed that we could **reduce energy consumption by close to 80%** by using our approach as opposed to using a large complex model.\n\nFurther, we extended this concept to the larger **MLOps pipeline**. To keep it simple, MLOps can be thought of as a set of practices that combines machine learning (ML), software engineering, and DevOps to streamline and automate the end-to-end lifecycle of ML development, deployment and management. MLOps pipeline typically enhances the maintainability of the ML system. However, periodically retraining ML models has also had an impact on the environment footprint.\n\nEven though it may enhance accuracy of the ML models, the accuracy needs to be also looked at from the perspective of impact on the environment. Sometimes for 1% increase in accuracy, tons of CO2 might be emitted^9^. To this end, we developed an approach to architect **self-adaptive MLOps pipelines** that decide when to re-train models or switch between models or use a more greener cloud instance for retraining by considering the cost, performance, accuracy and current carbon footprint. This work was published in the prestigious international conference on software architecture (ICSA 2024)^10^ where the work won the **best poster award**.\n\n## Onward and Forward\n\nCurrently, one of the biggest challenges in software engineering is about enhancing the sustainability of modern software systems, in particular AI systems. There are already efforts going on at a global level towards making softwares more green such as that of **Green Software Foundation** where different organizations are involved in defining green software engineering practices. There are also a lot of tools that have been made available both by the research and practitioner community to measure power, carbon footprint, etc. However, more concerted effort between the academic and research community is required to create a wider impact. Many times there is also a lack of awareness that needs to be addressed. As far as our research is concerned, we are working on extending our approach of model switching to Generative AI-based applications and to edge cloud continuum. Further, we are also extending our self-adaptive MLOps pipeline to support different types of AI systems. We are also collaborating with different research groups such as the **S2 group at VU Amsterdam**, the Netherlands to perform studies that can aid practitioners or researchers in building greener software systems. In addition to this, another compelling research angle that is being actively explored in collaboration with **Lloyds Technology Centre** is the development of practices that can enable architects to come up with green software design and deployment practices.\n\n---\n\n## References\n\n1. [Major tech outages in recent years - Reuters](https://www.reuters.com/technology/major-tech-outages-recent-years-2024-07-19)\n\n2. [AI model degradation study - Nature](https://www.nature.com/articles/s41598-022-15245-z)\n\n3. [Software emissions are equivalent to air, rail and shipping combined - Green Software Foundation](https://stateof.greensoftware.foundation/en/insights/software-emissions-are-equivalent-to-air-rail-shipping-combined/)\n\n4. C√°mara, J., Muccini, H. and Vaidhyanathan, K., 2020, March. *Quantitative verification-aided machine learning: A tandem approach for architecting self-adaptive IoT systems.* In 2020 IEEE International Conference on Software Architecture (ICSA) (pp. 11-22). IEEE.\n\n5. Karthik Vaidhyanathan, Mauro Caporuscio, Stefano Florio, and Henry Muccini. 2024. *ML-enabled Service Discovery for Microservice Architecture: a QoS Approach.* In Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing (SAC '24)\n\n6. Jain, P., Singhal, P., Pandey, D., Quatrocchi, G., Vaidhyanathan, K. (2025). *POSEIDON: Efficient Function Placement at the Edge Using Deep Reinforcement Learning.* In: Gaaloul, W., Sheng, M., Yu, Q., Yangui, S. (eds) Service-Oriented Computing. ICSOC 2024.\n\n7. [The true cost of generative AI data centers - Wired](https://www.wired.com/story/true-cost-generative-ai-data-centers-energy)\n\n8. M. Tedla, S. Kulkarni and K. Vaidhyanathan, *EcoMLS: A Self-Adaptation Approach for Architecting Green ML-Enabled Systems,* in 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C), [arXiv:2404.11411](https://arxiv.org/abs/2404.11411)\n\n9. [Energy and Policy Considerations for Deep Learning in NLP - arXiv](https://arxiv.org/abs/1906.02243)\n\n10. H. Bhatt, S. Arun, A. Kakran and K. Vaidhyanathan, *Towards Architecting Sustainable MLOps: A Self-Adaptation Approach,* in 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C) [arXiv:2404.04572](https://arxiv.org/pdf/2404.04572)",
    "author": "Dr. Karthik Vaidhyanathan",
    "date": "2025-01-17",
    "readTime": "10 min read"
  }
]